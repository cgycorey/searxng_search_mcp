"""
Demonstration of the complete search + analysis flow.

This example shows how the LLM would naturally chain the tools together
to provide comprehensive search results with intelligent analysis.
"""

from searxng_search_mcp.analyzer import SearchResultAnalyzer


def demonstrate_analysis_flow():
    """Demonstrate how search and analysis tools work together."""

    # Simulate search results from metasearch_web tool
    mock_search_results = [
        {
            "title": "Python Programming Tutorial - Complete Guide 2024",
            "url": "https://docs.python.org/tutorial",
            "content": "This comprehensive Python tutorial covers everything from basics to advanced concepts. Learn variables, functions, classes, and modern Python features.",
        },
        {
            "title": "JavaScript vs Python: Which is Better in 2024?",
            "url": "https://techcomparison.com/js-vs-python",
            "content": "Detailed comparison between JavaScript and Python for web development, data science, and machine learning applications.",
        },
        {
            "title": "Machine Learning with Python: A Beginner's Guide",
            "url": "https://ml-guide.com/python-ml",
            "content": "Learn machine learning fundamentals using Python. This guide covers scikit-learn, TensorFlow, and practical ML applications.",
        },
        {
            "title": "Python Web Development: Django vs Flask",
            "url": "https://webdev.com/python-frameworks",
            "content": "Comprehensive comparison of Django and Flask frameworks for Python web development. Performance, scalability, and use cases analyzed.",
        },
        {
            "title": "Python for Data Science: Complete Tutorial",
            "url": "https://datascience.com/python-tutorial",
            "content": "Master Python for data science with pandas, numpy, matplotlib, and statistical analysis techniques.",
        },
    ]

    # Initialize analyzer
    analyzer = SearchResultAnalyzer()

    print("üîç **Search Results Analysis Flow Demonstration**")
    print("=" * 60)

    # Step 1: Show raw search results (what metasearch_web returns)
    print("\n1Ô∏è‚É£ **Step 1: Raw Search Results (from metasearch_web)**")
    print(f"   Found {len(mock_search_results)} results")
    for i, result in enumerate(mock_search_results, 1):
        print(f"   {i}. {result['title']}")
        print(f"      URL: {result['url']}")
        print(f"      Content: {result['content'][:100]}...")
        print()

    # Step 2: Perform different types of analysis
    print("\n2Ô∏è‚É£ **Step 2: Analysis Results (from analyze_search_results)**")
    print("-" * 60)

    # Summary Analysis
    print("\nüìä **Summary Analysis:**")
    summary_result = analyzer.analyze_search_results(mock_search_results, "summary")
    print(f"   ‚Ä¢ Total results analyzed: {summary_result['metrics']['total_results']}")
    print(f"   ‚Ä¢ Unique domains: {summary_result['metrics']['unique_domains']}")
    print(f"   ‚Ä¢ Domain diversity: {summary_result['metrics']['domain_diversity']:.2f}")
    print(f"   ‚Ä¢ Main themes: {', '.join(summary_result['themes'])}")
    print(
        f"   ‚Ä¢ Top keywords: {', '.join([kw['keyword'] for kw in summary_result['top_keywords'][:5]])}"
    )

    # Sources Analysis
    print("\nüè¢ **Sources Analysis:**")
    sources_result = analyzer.analyze_search_results(mock_search_results, "sources")
    print(
        f"   ‚Ä¢ Source diversity score: {sources_result['diversity_metrics']['diversity_score']:.2f}"
    )
    print(
        f"   ‚Ä¢ Top domains: {', '.join([domain for domain, _ in sources_result['domain_distribution']['top_domains'][:3]])}"
    )

    # Show credibility scores
    print("   ‚Ä¢ Credibility scores:")
    for domain, score in list(sources_result["credibility_scores"].items())[:3]:
        credibility_level = (
            "High" if score >= 0.8 else "Medium" if score >= 0.6 else "Low"
        )
        print(f"     - {domain}: {credibility_level} ({score:.2f})")

    # Keywords Analysis
    print("\nüîë **Keywords Analysis:**")
    keywords_result = analyzer.analyze_search_results(mock_search_results, "keywords")
    print(f"   ‚Ä¢ Total unique keywords: {len(keywords_result['keyword_frequency'])}")
    print(f"   ‚Ä¢ Keyword clusters found: {len(keywords_result['keyword_clusters'])}")
    print("   ‚Ä¢ Top keywords by importance:")
    for keyword, importance in sorted(
        keywords_result["importance_scores"].items(), key=lambda x: x[1], reverse=True
    )[:5]:
        print(f"     - {keyword}: {importance:.3f}")

    # Trends Analysis
    print("\nüìà **Trends Analysis:**")
    trends_result = analyzer.analyze_search_results(mock_search_results, "trends")
    print(
        f"   ‚Ä¢ Recent content indicators: {trends_result['freshness_indicators']['fresh_content']}"
    )
    print(
        f"   ‚Ä¢ Evergreen content: {trends_result['freshness_indicators']['evergreen_content']}"
    )
    print(
        f"   ‚Ä¢ Emerging topics: {', '.join([topic['topic'] for topic in trends_result['emerging_topics'][:5]])}"
    )

    # Relevance Analysis
    print("\nüéØ **Relevance Analysis:**")
    relevance_result = analyzer.analyze_search_results(mock_search_results, "relevance")
    print(f"   ‚Ä¢ Average relevance score: {relevance_result['average_relevance']:.2f}")
    print(f"   ‚Ä¢ Average quality score: {relevance_result['average_quality']:.2f}")
    print("   ‚Ä¢ Relevance distribution:")
    for category, count in relevance_result["relevance_distribution"].items():
        print(f"     - {category}: {count} results")

    # Step 3: Show how LLM would combine everything
    print("\n3Ô∏è‚É£ **Step 3: How LLM Combines Search + Analysis**")
    print("-" * 60)
    print("The LLM would provide a response like:")
    print()
    print("üîç **Search Results for 'Python programming':**")
    print(
        "I found 5 relevant results about Python programming covering tutorials, comparisons, and applications."
    )
    print()
    print("üìä **Key Insights from Analysis:**")
    print(
        "‚Ä¢ **Main Themes**: Python is prominently featured across tutorials, comparisons, and applications"
    )
    print(
        "‚Ä¢ **Source Quality**: High diversity of sources with good credibility scores"
    )
    print(
        "‚Ä¢ **Content Focus**: Strong emphasis on web development, data science, and machine learning"
    )
    print(
        "‚Ä¢ **Trending Topics**: Python vs JavaScript comparisons and ML applications are emerging"
    )
    print()
    print("üè¢ **Top Sources:**")
    print("‚Ä¢ docs.python.org (High credibility - official documentation)")
    print("‚Ä¢ techcomparison.com (Medium credibility - comparison site)")
    print("‚Ä¢ ml-guide.com (Medium credibility - educational content)")
    print()
    print("üéØ **Recommendations:**")
    print("‚Ä¢ For learning: Start with official Python documentation")
    print(
        "‚Ä¢ For comparisons: JavaScript vs Python analysis shows Python excels in data science"
    )
    print(
        "‚Ä¢ For applications: Machine learning and web development are strong use cases"
    )


def demonstrate_llm_decision_flow():
    """Show how LLM decides to use analysis tool."""

    print("\n\nüß† **LLM Decision Flow for Tool Usage**")
    print("=" * 60)

    scenarios = [
        {
            "query": "Search for AI trends and analyze the results",
            "reasoning": [
                "‚úÖ User explicitly requests 'analyze the results'",
                "‚úÖ Call metasearch_web('AI trends') first",
                "‚úÖ Then call analyze_search_results(results, 'summary')",
                "‚úÖ Provide combined search + analysis response",
            ],
        },
        {
            "query": "Find information about climate change and check source credibility",
            "reasoning": [
                "‚úÖ User wants to 'check source credibility'",
                "‚úÖ Call metasearch_web('climate change') first",
                "‚úÖ Then call analyze_search_results(results, 'sources')",
                "‚úÖ Focus response on credibility assessment",
            ],
        },
        {
            "query": "What are the emerging topics in machine learning?",
            "reasoning": [
                "‚úÖ User asks for 'emerging topics' (trend analysis)",
                "‚úÖ Call metasearch_web('machine learning topics') first",
                "‚úÖ Then call analyze_search_results(results, 'trends')",
                "‚úÖ Highlight emerging topics and patterns",
            ],
        },
        {
            "query": "Search for Python programming tutorials",
            "reasoning": [
                "‚ùå User only requests search, no analysis mentioned",
                "‚úÖ Call only metasearch_web('Python programming tutorials')",
                "‚ùå Do NOT call analysis tool unless user follows up",
            ],
        },
    ]

    for i, scenario in enumerate(scenarios, 1):
        print(f"\n{i}. **Query:** '{scenario['query']}'")
        print("   **LLM Reasoning:**")
        for step in scenario["reasoning"]:
            print(f"   {step}")

    print("\nüéØ **Key Decision Factors:**")
    print("‚Ä¢ User explicitly mentions analysis keywords ‚Üí Use analysis tool")
    print("‚Ä¢ User asks for insights/patterns ‚Üí Use analysis tool")
    print("‚Ä¢ User requests source evaluation ‚Üí Use analysis tool with 'sources' type")
    print("‚Ä¢ User wants trends/comparisons ‚Üí Use analysis tool with 'trends' type")
    print("‚Ä¢ User only wants raw search results ‚Üí Skip analysis tool")


if __name__ == "__main__":
    demonstrate_analysis_flow()
    demonstrate_llm_decision_flow()
